{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TorchTensor学习+AdderNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC6-NgjEZQi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "x=torch.Tensor([[2,7,9,1],[7,1,1,8],[3,7,9,4],[5,0,3,2]])\n",
        "print(x)\n",
        "z=torch.ones((4,4))\n",
        "print(z)\n",
        "y=torch.mul(x,z)  #对应元素相乘\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ZehkSn9qhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "a=torch.Tensor([[1,2],[3,4]])\n",
        "b=torch.Tensor([[1,2,3],[3,2,1]])\n",
        "print(torch.mm(a,b))   #矩阵乘积"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArgJDaxp_RXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "x=torch.Tensor([[2,7,9,1],[7,1,1,8],[3,7,9,4],[5,0,3,2]])\n",
        "print(x)\n",
        "print(x.size())\n",
        "print(\"---------------------------------------------\")\n",
        "y=x.view(16)\n",
        "print(y)\n",
        "print(y.size())\n",
        "print(x.size())   #原始size并未被改变\n",
        "print(\"---------------------------------------------\")\n",
        "z=x.view((8,-1))  #-1代表根据提供的一个维度自己推算\n",
        "print(z)\n",
        "print(z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EISralT0AzTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "a349e4a7-6d14-49a9-d489-60b8edbdfe0f"
      },
      "source": [
        "#1、下面研究一下选取任意行列，并尝试卷积操作，手动/自动\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "x=torch.Tensor([[2,7,9,1],[7,1,1,8],[3,7,9,4],[5,0,3,2]])\n",
        "print(\"x的值：\\n\",x)\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"x第一个3x3的块：\\n\",x[0:3,0:3]) #选取第一个3x3的块\n",
        "\n",
        "print(\"\\n==============================================================================\\n\")\n",
        "#手动来一次卷积\n",
        "print(\"手动来卷积：\")\n",
        "kernel=torch.Tensor([[1,0,1],[0,1,0],[1,0,1]])\n",
        "t=x[0:3,0:3]\n",
        "conv=t.mul(kernel)\n",
        "print(\"第一个3x3块进行卷积操作：\\n\",conv)\n",
        "print(\"卷积结果：\\n\",float(conv.sum()))\n",
        "print(\"---------------------------------------------\")\n",
        "t=x[0:3,1:4]\n",
        "conv=t.mul(kernel)\n",
        "print(\"卷积结果：\\n\",float(conv.sum()))\n",
        "print(\"---------------------------------------------\")\n",
        "t=x[1:4,0:3]\n",
        "conv=t.mul(kernel)\n",
        "print(\"卷积结果：\\n\",float(conv.sum()))\n",
        "print(\"---------------------------------------------\")\n",
        "t=x[1:4,1:4]\n",
        "conv=t.mul(kernel)\n",
        "print(\"卷积结果：\\n\",float(conv.sum()))\n",
        "\n",
        "print(\"\\n==============================================================================\\n\")\n",
        "t=x[0:3,0:3]\n",
        "conv=t-kernel\n",
        "conv=torch.abs(conv)\n",
        "print(-conv.sum())\n",
        "\n",
        "t=x[0:3,1:4]\n",
        "conv=t-kernel\n",
        "conv=torch.abs(conv)\n",
        "print(-conv.sum())\n",
        "\n",
        "t=x[1:4,0:3]\n",
        "conv=t-kernel\n",
        "conv=torch.abs(conv)\n",
        "print(-conv.sum())\n",
        "\n",
        "t=x[1:4,1:4]\n",
        "conv=t-kernel\n",
        "conv=torch.abs(conv)\n",
        "print(-conv.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x的值：\n",
            " tensor([[2., 7., 9., 1.],\n",
            "        [7., 1., 1., 8.],\n",
            "        [3., 7., 9., 4.],\n",
            "        [5., 0., 3., 2.]])\n",
            "---------------------------------------------\n",
            "x第一个3x3的块：\n",
            " tensor([[2., 7., 9.],\n",
            "        [7., 1., 1.],\n",
            "        [3., 7., 9.]])\n",
            "\n",
            "==============================================================================\n",
            "\n",
            "手动来卷积：\n",
            "第一个3x3块进行卷积操作：\n",
            " tensor([[2., 0., 9.],\n",
            "        [0., 1., 0.],\n",
            "        [3., 0., 9.]])\n",
            "卷积结果：\n",
            " 24.0\n",
            "---------------------------------------------\n",
            "卷积结果：\n",
            " 20.0\n",
            "---------------------------------------------\n",
            "卷积结果：\n",
            " 23.0\n",
            "---------------------------------------------\n",
            "卷积结果：\n",
            " 20.0\n",
            "\n",
            "==============================================================================\n",
            "\n",
            "tensor(-41.)\n",
            "tensor(-42.)\n",
            "tensor(-31.)\n",
            "tensor(-32.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OiDAA1qFzWS",
        "colab_type": "code",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d0b93d2a-cbb9-4861-ea58-373f6c4e9ab5"
      },
      "source": [
        "#2、固定卷积核，自动卷积\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "x=torch.Tensor([[2,7,9,1],[7,1,1,8],[3,7,9,4],[5,0,3,2]]).unsqueeze(0).unsqueeze(0)\n",
        "print(\"x的值：\\n\",x)\n",
        "kernel=torch.Tensor([[1,0,1],[0,1,0],[1,0,1]]).unsqueeze(0).unsqueeze(0)\n",
        "#因为在实际应用时tensor一般是四维的，所以使用unsqueeze()拓展维度\n",
        "\n",
        "#想要使用自己的kernel，不能用nn.conv2d，要用F中的\n",
        "#参考https://blog.csdn.net/u013289254/article/details/103896635\n",
        "print(\"\\n===============================================================================\\n\")\n",
        "print(\"自动卷积：\")\n",
        "# torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
        "output=F.conv2d(x,kernel)\n",
        "print(output)   #发现结果和上面一样"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x的值：\n",
            " tensor([[[[2., 7., 9., 1.],\n",
            "          [7., 1., 1., 8.],\n",
            "          [3., 7., 9., 4.],\n",
            "          [5., 0., 3., 2.]]]])\n",
            "\n",
            "===============================================================================\n",
            "\n",
            "自动卷积：\n",
            "tensor([[[[24., 20.],\n",
            "          [23., 20.]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqOsCa5lLEKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3、下面尝试使用图片进行卷积，并测试AdderNet()\n",
        "# 图片的读取参考https://www.cnblogs.com/yinxiangnan-charles/p/5928689.html\n",
        "# ————————————————————使用PIL————————————————————————\n",
        "from PIL import Image\n",
        "im = Image.open('1.jpg')\n",
        "im.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "4IMSIlkG0IST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#——————————————————使用matplotlib————————————————————\n",
        "import matplotlib.pyplot as plt # plt 用于显示图片\n",
        "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
        "import numpy as np\n",
        "#这种方式图片可以直接显示\n",
        "air = mpimg.imread('1.jpg') # 读取和代码处于同一目录下的 lena.png\n",
        "plt.imshow(air)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "img=np.array(air)\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Ne0-qED00ISV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c9508a9-531e-4f07-e554-c85b4bed3df1"
      },
      "source": [
        "#——————————————————使用CV——————————————————\n",
        "import cv2\n",
        "import numpy as np\n",
        "imgcv=cv2.imread('1.jpg')\n",
        "#cv2.imshow('airplane', imgcv)\n",
        "#调整图片大小\n",
        "imgcv2 = cv2.resize(imgcv, (256,256), interpolation=cv2.INTER_CUBIC)  \n",
        "#cv2.imshow('resize',imgcv2)\n",
        "#转为灰度图\n",
        "img_gray = cv2.cvtColor(imgcv2,cv2.COLOR_RGB2GRAY)\n",
        "print(img_gray.shape)\n",
        "#cv2.imshow('gray',img_gray)\n",
        "#cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "qrRG8bAN0ISX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#测试矩阵的可视化，以为后面卷积后特征可视化做准备\n",
        "import numpy as np\n",
        "import cv2\n",
        "#随机生成矩阵，可视化\n",
        "tst=np.random.randint(0,256,(128,128,3),dtype=np.uint8) #cv支持unit8和float32 \n",
        "cv2.imshow('tst',tst)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ZXabP_r60ISY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6449e040-0406-46cb-b577-6bdf9675b9fa"
      },
      "source": [
        "#4、将上述图片转为tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "x=torch.Tensor([[2,7,9,1],[7,1,1,8],[3,7,9,4],[5,0,3,2]]).unsqueeze(0).unsqueeze(0)\n",
        "#img_t=torch.from_numpy(img_gray).unsqueeze(0).unsqueeze(0).float()\n",
        "#img_t=torch.FloatTensor(img_gray).unsqueeze(0).unsqueeze(0)\n",
        "print(img_t.size())\n",
        "#构造两个边缘检测卷积核，sobel\n",
        "kernel_sobel_x=torch.Tensor([[-1,0,1],[-2,0,2],[-1,0,1]]).unsqueeze(0).unsqueeze(0)\n",
        "kernel_sobel_y=torch.Tensor([[1,2,1],[0,0,0],[-1,-2,-1]]).unsqueeze(0).unsqueeze(0)\n",
        "#kernel_sobel_x=kernel_sobel_x.byte()     \n",
        "#kernel_sobel_y=kernel_sobel_y.byte()                         \n",
        "output=F.conv2d(img_t,kernel_sobel_x).squeeze(0).squeeze(0)\n",
        "output=output.numpy()\n",
        "#cv2.imshow('conv',output)\n",
        "#cv2.waitKey(0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7SPXq6B0ISa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "4877adc7-2b70-4951-f14f-4a0a9c946311"
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as f\n",
        " \n",
        "x = torch.arange(0, 1*3*15*15).float()\n",
        "x = x.view(1,3,15,15)\n",
        "print(x)\n",
        "x1 = f.unfold(x, kernel_size=3, dilation=1, stride=1)\n",
        "print(x1.shape)\n",
        "B, C_kh_kw, L = x1.size()\n",
        "x1 = x1.permute(0, 2, 1)\n",
        "x1 = x1.view(B, L, -1, 3, 3)\n",
        "print(x1)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n",
            "tensor([[[[ 0.,  1.],\n",
            "          [ 2.,  3.]],\n",
            "\n",
            "         [[ 4.,  5.],\n",
            "          [ 6.,  7.]],\n",
            "\n",
            "         [[ 8.,  9.],\n",
            "          [10., 11.]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itGvy8OIce1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b082409c-49d9-4413-9e1c-c31e1f322713"
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as f\n",
        "x=torch.Tensor([[[1,2,3],[4,5,6]]])\n",
        "print(x.size())\n",
        "x=x.permute(2,1,0)\n",
        "print(x.size())\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 3])\n",
            "torch.Size([3, 2, 1])\n",
            "tensor([[[1.],\n",
            "         [4.]],\n",
            "\n",
            "        [[2.],\n",
            "         [5.]],\n",
            "\n",
            "        [[3.],\n",
            "         [6.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_wxRQVhdTN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fee65adf-3d58-44ce-c0e7-7d9e004f42c1"
      },
      "source": [
        "! python /content/AdderNet-master/resnet50.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): adder2d()\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): adder2d()\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): adder2d()\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): adder2d()\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): adder2d()\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): adder2d()\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): adder2d()\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (bn2): BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIkl0Urchm-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cc0a07ed-c443-4990-a2ff-b522d72be5f2"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "x=torch.Tensor([[1,0,0,0,1],[0,2,0,2,0],[0,0,8,0,0],[0,2,0,2,0],[1,0,0,0,1]]).unsqueeze(0).unsqueeze(0)\n",
        "print(\"x的值：\\n\",x)\n",
        "kernel=torch.Tensor([[0,1,0],[1,-4,1],[0,1,0]]).unsqueeze(0).unsqueeze(0)\n",
        "#因为在实际应用时tensor一般是四维的，所以使用unsqueeze()拓展维度\n",
        "\n",
        "#想要使用自己的kernel，不能用nn.conv2d，要用F中的\n",
        "#参考https://blog.csdn.net/u013289254/article/details/103896635\n",
        "print(\"\\n===============================================================================\\n\")\n",
        "print(\"自动卷积：\")\n",
        "# torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
        "output=F.conv2d(x,kernel)\n",
        "print(output)   #发现结果和上面一样"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x的值：\n",
            " tensor([[[[1., 0., 0., 0., 1.],\n",
            "          [0., 2., 0., 2., 0.],\n",
            "          [0., 0., 8., 0., 0.],\n",
            "          [0., 2., 0., 2., 0.],\n",
            "          [1., 0., 0., 0., 1.]]]])\n",
            "\n",
            "===============================================================================\n",
            "\n",
            "自动卷积：\n",
            "tensor([[[[ -8.,  12.,  -8.],\n",
            "          [ 12., -32.,  12.],\n",
            "          [ -8.,  12.,  -8.]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}